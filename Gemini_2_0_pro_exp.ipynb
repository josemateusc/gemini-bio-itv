{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "JGnl4_pUwbse",
        "AXGH94I0nzi6",
        "NQLxcjVsxbiC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95a54df98dff451bbaa86544e60d7728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c4c74bb9c074112b91f726088deb58a",
              "IPY_MODEL_821d19d97380413d84e081613e61c3ee",
              "IPY_MODEL_70778faf5e6c4c45981bdb15d7a53ff0"
            ],
            "layout": "IPY_MODEL_c5c0f5ee208e4cadbe9c8edcc7725228"
          }
        },
        "3c4c74bb9c074112b91f726088deb58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb0ed883fe59477d944b724243381f31",
            "placeholder": "​",
            "style": "IPY_MODEL_ca55b33f739c4b559124b3d6b7181e41",
            "value": "OpenBioLLM-Llama3-8B.Q4_K_M.gguf: 100%"
          }
        },
        "821d19d97380413d84e081613e61c3ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a780f269d454784963311ac422a23b4",
            "max": 4921246592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ee380a2be494aada0cef494e2a5fa3c",
            "value": 4921246592
          }
        },
        "70778faf5e6c4c45981bdb15d7a53ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b03417ebe2c4a578156b2768406b4e4",
            "placeholder": "​",
            "style": "IPY_MODEL_f4d2fe518c484ee196ac39df28461162",
            "value": " 4.92G/4.92G [03:32&lt;00:00, 22.3MB/s]"
          }
        },
        "c5c0f5ee208e4cadbe9c8edcc7725228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb0ed883fe59477d944b724243381f31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca55b33f739c4b559124b3d6b7181e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a780f269d454784963311ac422a23b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ee380a2be494aada0cef494e2a5fa3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b03417ebe2c4a578156b2768406b4e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4d2fe518c484ee196ac39df28461162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizando a API do Gemini"
      ],
      "metadata": {
        "id": "8muXVywGnt6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurando o ambiente"
      ],
      "metadata": {
        "id": "g8B7cp1Tnwit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Insira sua API Key\n",
        "api_key = \"AIzaSyC6Y9o0OnMBTCTC4IfF79OJf2rvwXxzKqk\"  #@param {type:\"string\"}\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=api_key)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-pro-exp-02-05\",\n",
        "    contents=\"O que é a célula HeLa?\",\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-XXQD5LtWsP",
        "outputId": "3487fbb1-c44f-4995-c2ad-445798a3a77b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As células HeLa são uma linhagem de células imortais, o que significa que podem se dividir e multiplicar indefinidamente em laboratório sob condições adequadas. Elas são um dos tipos de células humanas mais antigos e mais comumente usados em pesquisa científica.\n",
            "\n",
            "**Origem:**\n",
            "\n",
            "As células HeLa foram obtidas de Henrietta Lacks, uma mulher afro-americana que morreu de câncer cervical em 1951. Uma amostra de seu tumor foi coletada sem seu consentimento ou conhecimento (o que era uma prática comum na época, mas hoje é considerado antiético). O Dr. George Gey, um pesquisador do Hospital Johns Hopkins, descobriu que essas células eram únicas: elas se reproduziam rapidamente e não morriam após algumas divisões, como as células normais.\n",
            "\n",
            "**Importância na Pesquisa:**\n",
            "\n",
            "As células HeLa foram (e continuam sendo) extremamente importantes para a ciência e a medicina, contribuindo para avanços significativos em diversas áreas:\n",
            "\n",
            "*   **Desenvolvimento de vacinas:** Foram cruciais no desenvolvimento da vacina contra a poliomielite e desempenharam um papel importante no desenvolvimento de vacinas contra outras doenças.\n",
            "*   **Pesquisa sobre o câncer:** Permitiram estudar o crescimento e a propagação de células cancerígenas, bem como testar a eficácia de tratamentos contra o câncer.\n",
            "*   **Estudo de doenças infecciosas:** Foram usadas para estudar vírus como o HIV, Zika, herpes e muitos outros.\n",
            "*   **Pesquisa genética:** Ajudaram a mapear o genoma humano e a entender como os genes funcionam.\n",
            "*   **Testes de toxicidade:** São usadas para testar a segurança de medicamentos, cosméticos e outros produtos.\n",
            "* Virologia, pesquisa do câncer, mapeamento genético, e, por causa da sua capacidade de dividir infinitamente, têm sido usadas em incontáveis experimentos, sendo uma das principais ferramentas da biologia celular.\n",
            "\n",
            "**Controvérsias:**\n",
            "\n",
            "A história das células HeLa também é marcada por controvérsias éticas:\n",
            "\n",
            "*   **Falta de consentimento:** Como mencionado, as células foram coletadas sem o consentimento de Henrietta Lacks ou de sua família.\n",
            "*   **Privacidade:** O genoma das células HeLa foi publicado, o que levantou preocupações sobre a privacidade genética da família Lacks.\n",
            "*   **Lucro:** Empresas lucraram com a comercialização de produtos derivados das células HeLa, enquanto a família Lacks não recebeu nenhuma compensação financeira por muitos anos.\n",
            "\n",
            "A história de Henrietta Lacks e suas células imortais foi retratada no livro \"A Vida Imortal de Henrietta Lacks\" (The Immortal Life of Henrietta Lacks), de Rebecca Skloot, e em um filme homônimo. A publicação do livro ajudou a trazer à tona as questões éticas e a iniciar um diálogo sobre consentimento informado, privacidade e justiça na pesquisa médica.\n",
            "\n",
            "Em resumo, as células HeLa são uma linhagem celular imortal de enorme importância para a pesquisa científica, mas sua história também levanta questões éticas importantes sobre consentimento, privacidade e justiça na pesquisa.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando uma função como a documentação mostra para utilizar o system:"
      ],
      "metadata": {
        "id": "JGnl4_pUwbse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "def generate(system, prompt):\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    model = \"gemini-2.0-pro-exp-02-05\"\n",
        "\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[types.Part.from_text(text=prompt)]\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=1,\n",
        "        top_p=0.95,\n",
        "        top_k=64,\n",
        "        max_output_tokens=8192,\n",
        "        response_mime_type=\"text/plain\",\n",
        "        system_instruction=[types.Part.from_text(text=system)]\n",
        "    )\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    )\n",
        "\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "FDFpqqhevlbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gerando os prompts"
      ],
      "metadata": {
        "id": "AXGH94I0nzi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_msg = \"Você é um biólogo muito experiente.\"\n",
        "prompt = \"O que é a célula HeLa?\"\n",
        "result = generate(system_msg, prompt)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLGAr_NkwVKm",
        "outputId": "77256ca0-1234-4e13-b25a-2d80ad966be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro, posso explicar o que é a célula HeLa.\n",
            "\n",
            "As células HeLa são uma linhagem de células imortais usadas em pesquisas científicas. Elas são o tipo mais antigo e mais comumente usado de linhagem de células humanas. A linhagem foi derivada de células de câncer cervical retiradas em 8 de fevereiro de 1951[1] de Henrietta Lacks, uma paciente que acabou morrendo de câncer em 4 de outubro de 1951.\n",
            "\n",
            "**Características principais das células HeLa**\n",
            "\n",
            "*   **Imortal:** Ao contrário das células normais, que têm uma vida útil limitada, as células HeLa não sofrem senescência programada (limite de Hayflick) e podem se dividir indefinidamente sob as condições corretas. Isso se deve à atividade da enzima telomerase, que evita o encurtamento gradual dos telômeros que ocorre durante a divisão celular.\n",
            "*   **Derivado do câncer:** As células HeLa são derivadas de um câncer cervical particularmente agressivo causado pelo papilomavírus humano 18 (HPV-18). Isso as torna anormais em muitos aspectos. Elas têm um número anormal de cromossomos (cariótipo) e sofrem mutações que as tornam diferentes das células cervicais normais.\n",
            "*   **Facilidade de uso:** As células HeLa se mostraram notavelmente duráveis ​​e fáceis de cultivar em cultura, o que as tornou muito populares para pesquisas. Elas se reproduzem rapidamente e não requerem condições altamente especializadas.\n",
            "*   **Uso generalizado:** As células HeLa têm sido usadas em uma ampla variedade de pesquisas, incluindo:\n",
            "    *   **Desenvolvimento da vacina contra a poliomielite:** As células HeLa foram cruciais para o desenvolvimento da vacina contra a poliomielite de Jonas Salk. Elas forneceram um sistema para cultivar grandes quantidades do vírus, que era necessário para a produção da vacina.\n",
            "    *   **Pesquisa sobre o câncer:** Elas têm sido amplamente utilizadas para estudar os mecanismos do câncer e testar potenciais tratamentos.\n",
            "    *   **Pesquisa em virologia:** As células HeLa são suscetíveis a uma ampla gama de vírus, tornando-as úteis no estudo de doenças infecciosas.\n",
            "    *   **Mapeamento genético:** As células HeLa ajudaram no mapeamento de genes e na compreensão da genética humana.\n",
            "    *   **Efeitos da radiação e toxinas:** Elas têm sido usadas para estudar os efeitos da radiação, toxinas e outras substâncias nas células.\n",
            "    *   **Pesquisa em viagens espaciais:** As células HeLa foram levadas ao espaço para estudar os efeitos da gravidade zero nas células.\n",
            "\n",
            "**Controvérsias e Questões Éticas**\n",
            "\n",
            "*   **Consentimento informado:** A questão ética mais importante é que as células de Henrietta Lacks foram retiradas e cultivadas sem seu conhecimento ou consentimento, o que era uma prática padrão na época, mas seria inaceitável pelos padrões atuais. A família Lacks não soube da existência da linhagem de células até a década de 1970.\n",
            "*   **Lucro:** A linhagem de células HeLa foi comercializada e gerou lucros significativos para empresas farmacêuticas e de biotecnologia, enquanto a família Lacks lutou com a pobreza e a falta de acesso aos cuidados de saúde.\n",
            "*   **Privacidade genética:** A publicação do genoma HeLa, embora útil para a pesquisa, também levantou preocupações sobre a privacidade da informação genética de Henrietta Lacks e de sua família.\n",
            "\n",
            "Houve esforços para abordar essas preocupações, incluindo a concessão de algum controle à família Lacks sobre o acesso aos dados do genoma HeLa e o reconhecimento das contribuições de Henrietta Lacks.\n",
            "\n",
            "Em resumo, as células HeLa são uma linhagem de células imortais derivadas de células de câncer cervical de Henrietta Lacks. Elas têm sido uma ferramenta inestimável para a pesquisa científica, contribuindo para muitos avanços importantes na medicina e biologia, mas sua história também é marcada por importantes questões éticas sobre consentimento, privacidade e justiça.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "joSbeZVi78IV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizando o openBioLLM no Colab"
      ],
      "metadata": {
        "id": "NQLxcjVsxbiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTBwpx-axe8J",
        "outputId": "a93e83dd-18ed-441e-9025-1d3a29a576c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.8.tar.gz (67.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (1.26.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.8-cp311-cp311-linux_x86_64.whl size=5959647 sha256=ce0ec4e98005925032cd77d95b311b959ef5615d26674c259023e67f09f22c9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/03/66/eb3810eafd55d921b2be32896d1f44313996982360663aa80b\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "llm = Llama.from_pretrained(\n",
        "\trepo_id=\"mradermacher/OpenBioLLM-Llama3-8B-GGUF\",\n",
        "\tfilename=\"OpenBioLLM-Llama3-8B.Q4_K_M.gguf\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "95a54df98dff451bbaa86544e60d7728",
            "3c4c74bb9c074112b91f726088deb58a",
            "821d19d97380413d84e081613e61c3ee",
            "70778faf5e6c4c45981bdb15d7a53ff0",
            "c5c0f5ee208e4cadbe9c8edcc7725228",
            "bb0ed883fe59477d944b724243381f31",
            "ca55b33f739c4b559124b3d6b7181e41",
            "2a780f269d454784963311ac422a23b4",
            "6ee380a2be494aada0cef494e2a5fa3c",
            "0b03417ebe2c4a578156b2768406b4e4",
            "f4d2fe518c484ee196ac39df28461162"
          ]
        },
        "collapsed": true,
        "id": "usRDsHb2xeWG",
        "outputId": "89b8955e-8cd3-4718-b8ae-91e25b7a42db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "OpenBioLLM-Llama3-8B.Q4_K_M.gguf:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95a54df98dff451bbaa86544e60d7728"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--mradermacher--OpenBioLLM-Llama3-8B-GGUF/snapshots/fae5e3dd76aefcb3000454343aeca70c001a9c35/./OpenBioLLM-Llama3-8B.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = .\n",
            "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,128256]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 128001\n",
            "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 4.58 GiB (4.89 BPW) \n",
            "load: missing pre-tokenizer type, using: 'default'\n",
            "load:                                             \n",
            "load: ************************************        \n",
            "load: GENERATION QUALITY WILL BE DEGRADED!        \n",
            "load: CONSIDER REGENERATING THE MODEL             \n",
            "load: ************************************        \n",
            "load:                                             \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 128255 '<|reserved_special_token_250|>' is not marked as EOG\n",
            "load: control token: 128254 '<|reserved_special_token_249|>' is not marked as EOG\n",
            "load: control token: 128253 '<|reserved_special_token_248|>' is not marked as EOG\n",
            "load: control token: 128251 '<|reserved_special_token_246|>' is not marked as EOG\n",
            "load: control token: 128246 '<|reserved_special_token_241|>' is not marked as EOG\n",
            "load: control token: 128243 '<|reserved_special_token_238|>' is not marked as EOG\n",
            "load: control token: 128240 '<|reserved_special_token_235|>' is not marked as EOG\n",
            "load: control token: 128239 '<|reserved_special_token_234|>' is not marked as EOG\n",
            "load: control token: 128238 '<|reserved_special_token_233|>' is not marked as EOG\n",
            "load: control token: 128237 '<|reserved_special_token_232|>' is not marked as EOG\n",
            "load: control token: 128232 '<|reserved_special_token_227|>' is not marked as EOG\n",
            "load: control token: 128228 '<|reserved_special_token_223|>' is not marked as EOG\n",
            "load: control token: 128227 '<|reserved_special_token_222|>' is not marked as EOG\n",
            "load: control token: 128225 '<|reserved_special_token_220|>' is not marked as EOG\n",
            "load: control token: 128222 '<|reserved_special_token_217|>' is not marked as EOG\n",
            "load: control token: 128215 '<|reserved_special_token_210|>' is not marked as EOG\n",
            "load: control token: 128211 '<|reserved_special_token_206|>' is not marked as EOG\n",
            "load: control token: 128210 '<|reserved_special_token_205|>' is not marked as EOG\n",
            "load: control token: 128204 '<|reserved_special_token_199|>' is not marked as EOG\n",
            "load: control token: 128203 '<|reserved_special_token_198|>' is not marked as EOG\n",
            "load: control token: 128201 '<|reserved_special_token_196|>' is not marked as EOG\n",
            "load: control token: 128197 '<|reserved_special_token_192|>' is not marked as EOG\n",
            "load: control token: 128196 '<|reserved_special_token_191|>' is not marked as EOG\n",
            "load: control token: 128195 '<|reserved_special_token_190|>' is not marked as EOG\n",
            "load: control token: 128193 '<|reserved_special_token_188|>' is not marked as EOG\n",
            "load: control token: 128191 '<|reserved_special_token_186|>' is not marked as EOG\n",
            "load: control token: 128190 '<|reserved_special_token_185|>' is not marked as EOG\n",
            "load: control token: 128185 '<|reserved_special_token_180|>' is not marked as EOG\n",
            "load: control token: 128184 '<|reserved_special_token_179|>' is not marked as EOG\n",
            "load: control token: 128182 '<|reserved_special_token_177|>' is not marked as EOG\n",
            "load: control token: 128181 '<|reserved_special_token_176|>' is not marked as EOG\n",
            "load: control token: 128177 '<|reserved_special_token_172|>' is not marked as EOG\n",
            "load: control token: 128176 '<|reserved_special_token_171|>' is not marked as EOG\n",
            "load: control token: 128175 '<|reserved_special_token_170|>' is not marked as EOG\n",
            "load: control token: 128174 '<|reserved_special_token_169|>' is not marked as EOG\n",
            "load: control token: 128173 '<|reserved_special_token_168|>' is not marked as EOG\n",
            "load: control token: 128172 '<|reserved_special_token_167|>' is not marked as EOG\n",
            "load: control token: 128168 '<|reserved_special_token_163|>' is not marked as EOG\n",
            "load: control token: 128167 '<|reserved_special_token_162|>' is not marked as EOG\n",
            "load: control token: 128166 '<|reserved_special_token_161|>' is not marked as EOG\n",
            "load: control token: 128165 '<|reserved_special_token_160|>' is not marked as EOG\n",
            "load: control token: 128162 '<|reserved_special_token_157|>' is not marked as EOG\n",
            "load: control token: 128159 '<|reserved_special_token_154|>' is not marked as EOG\n",
            "load: control token: 128155 '<|reserved_special_token_150|>' is not marked as EOG\n",
            "load: control token: 128153 '<|reserved_special_token_148|>' is not marked as EOG\n",
            "load: control token: 128152 '<|reserved_special_token_147|>' is not marked as EOG\n",
            "load: control token: 128151 '<|reserved_special_token_146|>' is not marked as EOG\n",
            "load: control token: 128148 '<|reserved_special_token_143|>' is not marked as EOG\n",
            "load: control token: 128146 '<|reserved_special_token_141|>' is not marked as EOG\n",
            "load: control token: 128144 '<|reserved_special_token_139|>' is not marked as EOG\n",
            "load: control token: 128143 '<|reserved_special_token_138|>' is not marked as EOG\n",
            "load: control token: 128141 '<|reserved_special_token_136|>' is not marked as EOG\n",
            "load: control token: 128139 '<|reserved_special_token_134|>' is not marked as EOG\n",
            "load: control token: 128138 '<|reserved_special_token_133|>' is not marked as EOG\n",
            "load: control token: 128135 '<|reserved_special_token_130|>' is not marked as EOG\n",
            "load: control token: 128133 '<|reserved_special_token_128|>' is not marked as EOG\n",
            "load: control token: 128132 '<|reserved_special_token_127|>' is not marked as EOG\n",
            "load: control token: 128131 '<|reserved_special_token_126|>' is not marked as EOG\n",
            "load: control token: 128130 '<|reserved_special_token_125|>' is not marked as EOG\n",
            "load: control token: 128128 '<|reserved_special_token_123|>' is not marked as EOG\n",
            "load: control token: 128125 '<|reserved_special_token_120|>' is not marked as EOG\n",
            "load: control token: 128121 '<|reserved_special_token_116|>' is not marked as EOG\n",
            "load: control token: 128120 '<|reserved_special_token_115|>' is not marked as EOG\n",
            "load: control token: 128119 '<|reserved_special_token_114|>' is not marked as EOG\n",
            "load: control token: 128116 '<|reserved_special_token_111|>' is not marked as EOG\n",
            "load: control token: 128112 '<|reserved_special_token_107|>' is not marked as EOG\n",
            "load: control token: 128109 '<|reserved_special_token_104|>' is not marked as EOG\n",
            "load: control token: 128107 '<|reserved_special_token_102|>' is not marked as EOG\n",
            "load: control token: 128106 '<|reserved_special_token_101|>' is not marked as EOG\n",
            "load: control token: 128105 '<|reserved_special_token_100|>' is not marked as EOG\n",
            "load: control token: 128103 '<|reserved_special_token_98|>' is not marked as EOG\n",
            "load: control token: 128100 '<|reserved_special_token_95|>' is not marked as EOG\n",
            "load: control token: 128099 '<|reserved_special_token_94|>' is not marked as EOG\n",
            "load: control token: 128098 '<|reserved_special_token_93|>' is not marked as EOG\n",
            "load: control token: 128094 '<|reserved_special_token_89|>' is not marked as EOG\n",
            "load: control token: 128088 '<|reserved_special_token_83|>' is not marked as EOG\n",
            "load: control token: 128087 '<|reserved_special_token_82|>' is not marked as EOG\n",
            "load: control token: 128086 '<|reserved_special_token_81|>' is not marked as EOG\n",
            "load: control token: 128084 '<|reserved_special_token_79|>' is not marked as EOG\n",
            "load: control token: 128082 '<|reserved_special_token_77|>' is not marked as EOG\n",
            "load: control token: 128078 '<|reserved_special_token_73|>' is not marked as EOG\n",
            "load: control token: 128075 '<|reserved_special_token_70|>' is not marked as EOG\n",
            "load: control token: 128073 '<|reserved_special_token_68|>' is not marked as EOG\n",
            "load: control token: 128072 '<|reserved_special_token_67|>' is not marked as EOG\n",
            "load: control token: 128070 '<|reserved_special_token_65|>' is not marked as EOG\n",
            "load: control token: 128065 '<|reserved_special_token_60|>' is not marked as EOG\n",
            "load: control token: 128064 '<|reserved_special_token_59|>' is not marked as EOG\n",
            "load: control token: 128062 '<|reserved_special_token_57|>' is not marked as EOG\n",
            "load: control token: 128060 '<|reserved_special_token_55|>' is not marked as EOG\n",
            "load: control token: 128059 '<|reserved_special_token_54|>' is not marked as EOG\n",
            "load: control token: 128057 '<|reserved_special_token_52|>' is not marked as EOG\n",
            "load: control token: 128056 '<|reserved_special_token_51|>' is not marked as EOG\n",
            "load: control token: 128054 '<|reserved_special_token_49|>' is not marked as EOG\n",
            "load: control token: 128051 '<|reserved_special_token_46|>' is not marked as EOG\n",
            "load: control token: 128043 '<|reserved_special_token_38|>' is not marked as EOG\n",
            "load: control token: 128042 '<|reserved_special_token_37|>' is not marked as EOG\n",
            "load: control token: 128041 '<|reserved_special_token_36|>' is not marked as EOG\n",
            "load: control token: 128040 '<|reserved_special_token_35|>' is not marked as EOG\n",
            "load: control token: 128035 '<|reserved_special_token_30|>' is not marked as EOG\n",
            "load: control token: 128033 '<|reserved_special_token_28|>' is not marked as EOG\n",
            "load: control token: 128032 '<|reserved_special_token_27|>' is not marked as EOG\n",
            "load: control token: 128029 '<|reserved_special_token_24|>' is not marked as EOG\n",
            "load: control token: 128025 '<|reserved_special_token_20|>' is not marked as EOG\n",
            "load: control token: 128024 '<|reserved_special_token_19|>' is not marked as EOG\n",
            "load: control token: 128021 '<|reserved_special_token_16|>' is not marked as EOG\n",
            "load: control token: 128020 '<|reserved_special_token_15|>' is not marked as EOG\n",
            "load: control token: 128019 '<|reserved_special_token_14|>' is not marked as EOG\n",
            "load: control token: 128018 '<|reserved_special_token_13|>' is not marked as EOG\n",
            "load: control token: 128015 '<|reserved_special_token_10|>' is not marked as EOG\n",
            "load: control token: 128013 '<|reserved_special_token_8|>' is not marked as EOG\n",
            "load: control token: 128012 '<|reserved_special_token_7|>' is not marked as EOG\n",
            "load: control token: 128010 '<|reserved_special_token_5|>' is not marked as EOG\n",
            "load: control token: 128005 '<|reserved_special_token_3|>' is not marked as EOG\n",
            "load: control token: 128004 '<|reserved_special_token_2|>' is not marked as EOG\n",
            "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
            "load: control token: 128249 '<|reserved_special_token_244|>' is not marked as EOG\n",
            "load: control token: 128187 '<|reserved_special_token_182|>' is not marked as EOG\n",
            "load: control token: 128180 '<|reserved_special_token_175|>' is not marked as EOG\n",
            "load: control token: 128134 '<|reserved_special_token_129|>' is not marked as EOG\n",
            "load: control token: 128179 '<|reserved_special_token_174|>' is not marked as EOG\n",
            "load: control token: 128037 '<|reserved_special_token_32|>' is not marked as EOG\n",
            "load: control token: 128045 '<|reserved_special_token_40|>' is not marked as EOG\n",
            "load: control token: 128089 '<|reserved_special_token_84|>' is not marked as EOG\n",
            "load: control token: 128212 '<|reserved_special_token_207|>' is not marked as EOG\n",
            "load: control token: 128104 '<|reserved_special_token_99|>' is not marked as EOG\n",
            "load: control token: 128205 '<|reserved_special_token_200|>' is not marked as EOG\n",
            "load: control token: 128142 '<|reserved_special_token_137|>' is not marked as EOG\n",
            "load: control token: 128028 '<|reserved_special_token_23|>' is not marked as EOG\n",
            "load: control token: 128126 '<|reserved_special_token_121|>' is not marked as EOG\n",
            "load: control token: 128198 '<|reserved_special_token_193|>' is not marked as EOG\n",
            "load: control token: 128071 '<|reserved_special_token_66|>' is not marked as EOG\n",
            "load: control token: 128092 '<|reserved_special_token_87|>' is not marked as EOG\n",
            "load: control token: 128183 '<|reserved_special_token_178|>' is not marked as EOG\n",
            "load: control token: 128140 '<|reserved_special_token_135|>' is not marked as EOG\n",
            "load: control token: 128226 '<|reserved_special_token_221|>' is not marked as EOG\n",
            "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
            "load: control token: 128052 '<|reserved_special_token_47|>' is not marked as EOG\n",
            "load: control token: 128053 '<|reserved_special_token_48|>' is not marked as EOG\n",
            "load: control token: 128058 '<|reserved_special_token_53|>' is not marked as EOG\n",
            "load: control token: 128150 '<|reserved_special_token_145|>' is not marked as EOG\n",
            "load: control token: 128149 '<|reserved_special_token_144|>' is not marked as EOG\n",
            "load: control token: 128209 '<|reserved_special_token_204|>' is not marked as EOG\n",
            "load: control token: 128169 '<|reserved_special_token_164|>' is not marked as EOG\n",
            "load: control token: 128157 '<|reserved_special_token_152|>' is not marked as EOG\n",
            "load: control token: 128038 '<|reserved_special_token_33|>' is not marked as EOG\n",
            "load: control token: 128178 '<|reserved_special_token_173|>' is not marked as EOG\n",
            "load: control token: 128091 '<|reserved_special_token_86|>' is not marked as EOG\n",
            "load: control token: 128115 '<|reserved_special_token_110|>' is not marked as EOG\n",
            "load: control token: 128233 '<|reserved_special_token_228|>' is not marked as EOG\n",
            "load: control token: 128145 '<|reserved_special_token_140|>' is not marked as EOG\n",
            "load: control token: 128039 '<|reserved_special_token_34|>' is not marked as EOG\n",
            "load: control token: 128136 '<|reserved_special_token_131|>' is not marked as EOG\n",
            "load: control token: 128170 '<|reserved_special_token_165|>' is not marked as EOG\n",
            "load: control token: 128236 '<|reserved_special_token_231|>' is not marked as EOG\n",
            "load: control token: 128154 '<|reserved_special_token_149|>' is not marked as EOG\n",
            "load: control token: 128049 '<|reserved_special_token_44|>' is not marked as EOG\n",
            "load: control token: 128023 '<|reserved_special_token_18|>' is not marked as EOG\n",
            "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
            "load: control token: 128016 '<|reserved_special_token_11|>' is not marked as EOG\n",
            "load: control token: 128113 '<|reserved_special_token_108|>' is not marked as EOG\n",
            "load: control token: 128158 '<|reserved_special_token_153|>' is not marked as EOG\n",
            "load: control token: 128223 '<|reserved_special_token_218|>' is not marked as EOG\n",
            "load: control token: 128156 '<|reserved_special_token_151|>' is not marked as EOG\n",
            "load: control token: 128008 '<|reserved_special_token_4|>' is not marked as EOG\n",
            "load: control token: 128085 '<|reserved_special_token_80|>' is not marked as EOG\n",
            "load: control token: 128160 '<|reserved_special_token_155|>' is not marked as EOG\n",
            "load: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
            "load: control token: 128110 '<|reserved_special_token_105|>' is not marked as EOG\n",
            "load: control token: 128247 '<|reserved_special_token_242|>' is not marked as EOG\n",
            "load: control token: 128122 '<|reserved_special_token_117|>' is not marked as EOG\n",
            "load: control token: 128050 '<|reserved_special_token_45|>' is not marked as EOG\n",
            "load: control token: 128221 '<|reserved_special_token_216|>' is not marked as EOG\n",
            "load: control token: 128244 '<|reserved_special_token_239|>' is not marked as EOG\n",
            "load: control token: 128248 '<|reserved_special_token_243|>' is not marked as EOG\n",
            "load: control token: 128213 '<|reserved_special_token_208|>' is not marked as EOG\n",
            "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
            "load: control token: 128208 '<|reserved_special_token_203|>' is not marked as EOG\n",
            "load: control token: 128074 '<|reserved_special_token_69|>' is not marked as EOG\n",
            "load: control token: 128234 '<|reserved_special_token_229|>' is not marked as EOG\n",
            "load: control token: 128083 '<|reserved_special_token_78|>' is not marked as EOG\n",
            "load: control token: 128224 '<|reserved_special_token_219|>' is not marked as EOG\n",
            "load: control token: 128055 '<|reserved_special_token_50|>' is not marked as EOG\n",
            "load: control token: 128097 '<|reserved_special_token_92|>' is not marked as EOG\n",
            "load: control token: 128206 '<|reserved_special_token_201|>' is not marked as EOG\n",
            "load: control token: 128081 '<|reserved_special_token_76|>' is not marked as EOG\n",
            "load: control token: 128068 '<|reserved_special_token_63|>' is not marked as EOG\n",
            "load: control token: 128067 '<|reserved_special_token_62|>' is not marked as EOG\n",
            "load: control token: 128046 '<|reserved_special_token_41|>' is not marked as EOG\n",
            "load: control token: 128194 '<|reserved_special_token_189|>' is not marked as EOG\n",
            "load: control token: 128069 '<|reserved_special_token_64|>' is not marked as EOG\n",
            "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
            "load: control token: 128220 '<|reserved_special_token_215|>' is not marked as EOG\n",
            "load: control token: 128214 '<|reserved_special_token_209|>' is not marked as EOG\n",
            "load: control token: 128108 '<|reserved_special_token_103|>' is not marked as EOG\n",
            "load: control token: 128200 '<|reserved_special_token_195|>' is not marked as EOG\n",
            "load: control token: 128048 '<|reserved_special_token_43|>' is not marked as EOG\n",
            "load: control token: 128027 '<|reserved_special_token_22|>' is not marked as EOG\n",
            "load: control token: 128114 '<|reserved_special_token_109|>' is not marked as EOG\n",
            "load: control token: 128235 '<|reserved_special_token_230|>' is not marked as EOG\n",
            "load: control token: 128252 '<|reserved_special_token_247|>' is not marked as EOG\n",
            "load: control token: 128199 '<|reserved_special_token_194|>' is not marked as EOG\n",
            "load: control token: 128129 '<|reserved_special_token_124|>' is not marked as EOG\n",
            "load: control token: 128245 '<|reserved_special_token_240|>' is not marked as EOG\n",
            "load: control token: 128164 '<|reserved_special_token_159|>' is not marked as EOG\n",
            "load: control token: 128124 '<|reserved_special_token_119|>' is not marked as EOG\n",
            "load: control token: 128102 '<|reserved_special_token_97|>' is not marked as EOG\n",
            "load: control token: 128036 '<|reserved_special_token_31|>' is not marked as EOG\n",
            "load: control token: 128229 '<|reserved_special_token_224|>' is not marked as EOG\n",
            "load: control token: 128163 '<|reserved_special_token_158|>' is not marked as EOG\n",
            "load: control token: 128127 '<|reserved_special_token_122|>' is not marked as EOG\n",
            "load: control token: 128111 '<|reserved_special_token_106|>' is not marked as EOG\n",
            "load: control token: 128231 '<|reserved_special_token_226|>' is not marked as EOG\n",
            "load: control token: 128188 '<|reserved_special_token_183|>' is not marked as EOG\n",
            "load: control token: 128061 '<|reserved_special_token_56|>' is not marked as EOG\n",
            "load: control token: 128137 '<|reserved_special_token_132|>' is not marked as EOG\n",
            "load: control token: 128093 '<|reserved_special_token_88|>' is not marked as EOG\n",
            "load: control token: 128095 '<|reserved_special_token_90|>' is not marked as EOG\n",
            "load: control token: 128189 '<|reserved_special_token_184|>' is not marked as EOG\n",
            "load: control token: 128090 '<|reserved_special_token_85|>' is not marked as EOG\n",
            "load: control token: 128147 '<|reserved_special_token_142|>' is not marked as EOG\n",
            "load: control token: 128219 '<|reserved_special_token_214|>' is not marked as EOG\n",
            "load: control token: 128230 '<|reserved_special_token_225|>' is not marked as EOG\n",
            "load: control token: 128217 '<|reserved_special_token_212|>' is not marked as EOG\n",
            "load: control token: 128031 '<|reserved_special_token_26|>' is not marked as EOG\n",
            "load: control token: 128030 '<|reserved_special_token_25|>' is not marked as EOG\n",
            "load: control token: 128250 '<|reserved_special_token_245|>' is not marked as EOG\n",
            "load: control token: 128192 '<|reserved_special_token_187|>' is not marked as EOG\n",
            "load: control token: 128096 '<|reserved_special_token_91|>' is not marked as EOG\n",
            "load: control token: 128186 '<|reserved_special_token_181|>' is not marked as EOG\n",
            "load: control token: 128207 '<|reserved_special_token_202|>' is not marked as EOG\n",
            "load: control token: 128171 '<|reserved_special_token_166|>' is not marked as EOG\n",
            "load: control token: 128080 '<|reserved_special_token_75|>' is not marked as EOG\n",
            "load: control token: 128077 '<|reserved_special_token_72|>' is not marked as EOG\n",
            "load: control token: 128101 '<|reserved_special_token_96|>' is not marked as EOG\n",
            "load: control token: 128079 '<|reserved_special_token_74|>' is not marked as EOG\n",
            "load: control token: 128216 '<|reserved_special_token_211|>' is not marked as EOG\n",
            "load: control token: 128014 '<|reserved_special_token_9|>' is not marked as EOG\n",
            "load: control token: 128047 '<|reserved_special_token_42|>' is not marked as EOG\n",
            "load: control token: 128202 '<|reserved_special_token_197|>' is not marked as EOG\n",
            "load: control token: 128044 '<|reserved_special_token_39|>' is not marked as EOG\n",
            "load: control token: 128161 '<|reserved_special_token_156|>' is not marked as EOG\n",
            "load: control token: 128017 '<|reserved_special_token_12|>' is not marked as EOG\n",
            "load: control token: 128066 '<|reserved_special_token_61|>' is not marked as EOG\n",
            "load: control token: 128242 '<|reserved_special_token_237|>' is not marked as EOG\n",
            "load: control token: 128118 '<|reserved_special_token_113|>' is not marked as EOG\n",
            "load: control token: 128076 '<|reserved_special_token_71|>' is not marked as EOG\n",
            "load: control token: 128034 '<|reserved_special_token_29|>' is not marked as EOG\n",
            "load: control token: 128241 '<|reserved_special_token_236|>' is not marked as EOG\n",
            "load: control token: 128026 '<|reserved_special_token_21|>' is not marked as EOG\n",
            "load: control token: 128218 '<|reserved_special_token_213|>' is not marked as EOG\n",
            "load: control token: 128063 '<|reserved_special_token_58|>' is not marked as EOG\n",
            "load: control token: 128117 '<|reserved_special_token_112|>' is not marked as EOG\n",
            "load: control token: 128011 '<|reserved_special_token_6|>' is not marked as EOG\n",
            "load: control token: 128022 '<|reserved_special_token_17|>' is not marked as EOG\n",
            "load: control token: 128123 '<|reserved_special_token_118|>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 256\n",
            "load: token to piece cache size = 0.8000 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 8192\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 500000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 8192\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 8B\n",
            "print_info: model params     = 8.03 B\n",
            "print_info: general.name     = .\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 128256\n",
            "print_info: n_merges         = 280147\n",
            "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
            "print_info: EOS token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOT token        = 128009 '<|eot_id|>'\n",
            "print_info: PAD token        = 128001 '<|end_of_text|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOG token        = 128009 '<|eot_id|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU\n",
            "load_tensors: layer   1 assigned to device CPU\n",
            "load_tensors: layer   2 assigned to device CPU\n",
            "load_tensors: layer   3 assigned to device CPU\n",
            "load_tensors: layer   4 assigned to device CPU\n",
            "load_tensors: layer   5 assigned to device CPU\n",
            "load_tensors: layer   6 assigned to device CPU\n",
            "load_tensors: layer   7 assigned to device CPU\n",
            "load_tensors: layer   8 assigned to device CPU\n",
            "load_tensors: layer   9 assigned to device CPU\n",
            "load_tensors: layer  10 assigned to device CPU\n",
            "load_tensors: layer  11 assigned to device CPU\n",
            "load_tensors: layer  12 assigned to device CPU\n",
            "load_tensors: layer  13 assigned to device CPU\n",
            "load_tensors: layer  14 assigned to device CPU\n",
            "load_tensors: layer  15 assigned to device CPU\n",
            "load_tensors: layer  16 assigned to device CPU\n",
            "load_tensors: layer  17 assigned to device CPU\n",
            "load_tensors: layer  18 assigned to device CPU\n",
            "load_tensors: layer  19 assigned to device CPU\n",
            "load_tensors: layer  20 assigned to device CPU\n",
            "load_tensors: layer  21 assigned to device CPU\n",
            "load_tensors: layer  22 assigned to device CPU\n",
            "load_tensors: layer  23 assigned to device CPU\n",
            "load_tensors: layer  24 assigned to device CPU\n",
            "load_tensors: layer  25 assigned to device CPU\n",
            "load_tensors: layer  26 assigned to device CPU\n",
            "load_tensors: layer  27 assigned to device CPU\n",
            "load_tensors: layer  28 assigned to device CPU\n",
            "load_tensors: layer  29 assigned to device CPU\n",
            "load_tensors: layer  30 assigned to device CPU\n",
            "load_tensors: layer  31 assigned to device CPU\n",
            "load_tensors: layer  32 assigned to device CPU\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:   CPU_Mapped model buffer size =  4685.30 MiB\n",
            "........................................................................................\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 512\n",
            "llama_init_from_model: n_ctx_per_seq = 512\n",
            "llama_init_from_model: n_batch       = 512\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 500000.0\n",
            "llama_init_from_model: freq_scale    = 1\n",
            "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
            "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
            "llama_init_from_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
            "llama_init_from_model:        CPU  output buffer size =     0.49 MiB\n",
            "llama_init_from_model:        CPU compute buffer size =   258.50 MiB\n",
            "llama_init_from_model: graph nodes  = 1030\n",
            "llama_init_from_model: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.padding_token_id': '128001', 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'llama.context_length': '8192', 'general.name': '.', 'llama.vocab_size': '128256', 'general.file_type': '15', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\"\n",
        "\n",
        "    Você é um <expert>biomolecular cientista especializado em genética e bioquímica.\n",
        "\n",
        "  <instruction>\n",
        "    Sua tarefa é classificar os seguintes genes e proteínas com base em sua principal função biológica.\n",
        "  </instruction>\n",
        "\n",
        "  <format>\n",
        "    Use a seguinte estrutura para sua resposta:\n",
        "    <classification>\n",
        "      <gene>Nome do gene/proteína</gene>\n",
        "      <function>Função principal</function>\n",
        "      <category>Categoria funcional</category>\n",
        "      <explanation>Breve explicação científica</explanation>\n",
        "    </classification>\n",
        "  </format>\n",
        "\n",
        "  <examples>\n",
        "    <example>\n",
        "      <gene>BRCA1</gene>\n",
        "      <function>Reparo de quebras na fita dupla do DNA</function>\n",
        "      <category>Reparo de DNA</category>\n",
        "      <explanation>BRCA1 é um gene supressor tumoral envolvido no reparo de quebras de fita dupla por recombinação homóloga. Mutações nesse gene aumentam o risco de câncer de mama e ovário.</explanation>\n",
        "    </example>\n",
        "    <example>\n",
        "      <gene>TP53</gene>\n",
        "      <function>Regulação do ciclo celular e apoptose</function>\n",
        "      <category>Supressor tumoral</category>\n",
        "      <explanation>TP53 codifica a proteína p53, um regulador chave da resposta ao estresse celular. Atua na indução da apoptose, reparo do DNA e parada do ciclo celular em resposta a danos genômicos.</explanation>\n",
        "    </example>\n",
        "  </examples>\n",
        "\n",
        "    Agora, classifique os seguintes genes e proteínas usando essa estrutura:\n",
        "      <gene>SOD1</gene>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TH3JFVuQFEhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm(\n",
        "\tprompt,\n",
        "\tmax_tokens=2048,\n",
        "\techo=True\n",
        ")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpKekH90xgsl",
        "outputId": "42830277-b5f0-46a3-b578-2af645dcb3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =  167519.79 ms\n",
            "llama_perf_context_print: prompt eval time =  167518.97 ms /   418 tokens (  400.76 ms per token,     2.50 tokens per second)\n",
            "llama_perf_context_print:        eval time =   53640.72 ms /    84 runs   (  638.58 ms per token,     1.57 tokens per second)\n",
            "llama_perf_context_print:       total time =  221269.20 ms /   502 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-7a98bf92-f017-4b20-972a-044f2e05c095', 'object': 'text_completion', 'created': 1742214983, 'model': '/root/.cache/huggingface/hub/models--mradermacher--OpenBioLLM-Llama3-8B-GGUF/snapshots/fae5e3dd76aefcb3000454343aeca70c001a9c35/./OpenBioLLM-Llama3-8B.Q4_K_M.gguf', 'choices': [{'text': '\"\\n\\n    Você é um <expert>biomolecular cientista especializado em genética e bioquímica.\\n\\n  <instruction>\\n    Sua tarefa é classificar os seguintes genes e proteínas com base em sua principal função biológica.\\n  </instruction>\\n\\n  <format>\\n    Use a seguinte estrutura para sua resposta:\\n    <classification>\\n      <gene>Nome do gene/proteína</gene>\\n      <function>Função principal</function>\\n      <category>Categoria funcional</category>\\n      <explanation>Breve explicação científica</explanation>\\n    </classification>\\n  </format>\\n\\n  <examples>\\n    <example>\\n      <gene>BRCA1</gene>\\n      <function>Reparo de quebras na fita dupla do DNA</function>\\n      <category>Reparo de DNA</category>\\n      <explanation>BRCA1 é um gene supressor tumoral envolvido no reparo de quebras de fita dupla por recombinação homóloga. Mutações nesse gene aumentam o risco de câncer de mama e ovário.</explanation>\\n    </example>\\n    <example>\\n      <gene>TP53</gene>\\n      <function>Regulação do ciclo celular e apoptose</function>\\n      <category>Supressor tumoral</category>\\n      <explanation>TP53 codifica a proteína p53, um regulador chave da resposta ao estresse celular. Atua na indução da apoptose, reparo do DNA e parada do ciclo celular em resposta a danos genômicos.</explanation>\\n    </example>\\n  </examples>\\n\\n    Agora, classifique os seguintes genes e proteínas usando essa estrutura:\\n      <gene>SOD1</gene>\\n      <function>Neutralização de radicais livres</function>\\n      <category>Antioxidante</category>\\n      <explanation>SOD1 codifica a proteína superóxido dismutase 1, que desempenha um papel crucial na neutralização de radicais livres, substâncias reativas que podem danificar células e organelos.</explanation>', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 418, 'completion_tokens': 84, 'total_tokens': 502}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "vWhnp_EixmiA",
        "outputId": "2f4ee61e-c06b-4b3c-9f5c-64106f7a0eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"\\n\\n    Você é um <expert>biomolecular cientista especializado em genética e bioquímica.\\n\\n  <instruction>\\n    Sua tarefa é classificar os seguintes genes e proteínas com base em sua principal função biológica.\\n  </instruction>\\n\\n  <format>\\n    Use a seguinte estrutura para sua resposta:\\n    <classification>\\n      <gene>Nome do gene/proteína</gene>\\n      <function>Função principal</function>\\n      <category>Categoria funcional</category>\\n      <explanation>Breve explicação científica</explanation>\\n    </classification>\\n  </format>\\n\\n  <examples>\\n    <example>\\n      <gene>BRCA1</gene>\\n      <function>Reparo de quebras na fita dupla do DNA</function>\\n      <category>Reparo de DNA</category>\\n      <explanation>BRCA1 é um gene supressor tumoral envolvido no reparo de quebras de fita dupla por recombinação homóloga. Mutações nesse gene aumentam o risco de câncer de mama e ovário.</explanation>\\n    </example>\\n    <example>\\n      <gene>TP53</gene>\\n      <function>Regulação do ciclo celular e apoptose</function>\\n      <category>Supressor tumoral</category>\\n      <explanation>TP53 codifica a proteína p53, um regulador chave da resposta ao estresse celular. Atua na indução da apoptose, reparo do DNA e parada do ciclo celular em resposta a danos genômicos.</explanation>\\n    </example>\\n  </examples>\\n\\n    Agora, classifique os seguintes genes e proteínas usando essa estrutura:\\n      <gene>SOD1</gene>\\n      <function>Neutralização de radicais livres</function>\\n      <category>Antioxidante</category>\\n      <explanation>SOD1 codifica a proteína superóxido dismutase 1, que desempenha um papel crucial na neutralização de radicais livres, substâncias reativas que podem danificar células e organelos.</explanation>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}